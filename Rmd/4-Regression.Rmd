```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

# Regressão - Fundamentos e Modelos

Exemplos alinhados aos slides de `4-Regressao.pdf`.  
Cada chunk indica o **slide** correspondente.

## Como ler este roteiro
Interprete os resultados em três ciclos:
1. ajuste do modelo;
2. diagnóstico/premissas;
3. comparação de desempenho em teste.
Esse ciclo ajuda a decidir quando aumentar complexidade.

## Configuração

Carregamos pacotes para três frentes: modelagem (`daltoolbox`), visualização (`ggplot2`) e manipulação de dados (`dplyr`), além do conjunto de dados `Boston` em `MASS`.  
Slides: 1–7.

```{r libraries}
# Slides 1–7: conceitos e taxonomia
library(daltoolbox)
library(ggplot2)
library(dplyr)
library(MASS)
```

## Conjunto de dados e divisao treino/teste

Usamos o `Boston Housing` para prever `medv` (valor mediano de imóveis).  
Neste ponto, a meta é entender estrutura de variáveis antes de modelar.

```{r data}
# Slides 10: conjunto de dados Boston Housing
data(Boston)
str(Boston)
head(Boston)
```

Com os dados inspecionados, definimos a divisão treino/teste e as métricas-base que serão reutilizadas em todo o roteiro.

```{r split}
# Slides 10: preparação treino/teste
set.seed(1)
split_random <- sample_random()
split_random <- train_test(split_random, Boston, perc = 0.7)
train <- split_random$train
test <- split_random$test

eval_reg <- function(model, y_true, y_pred, attribute = "medv") {
  # Alguns modelos (ex.: reg_lm) podem retornar NULL em evaluate(model, ...)
  eval <- evaluate(model, y_true, y_pred)
  if (is.null(eval) || is.null(eval$metrics)) {
    proxy <- regression(attribute)
    eval <- evaluate(proxy, as.vector(y_true), as.vector(y_pred))
  }
  eval
}
```

A avaliação será feita com `evaluate()` para manter o mesmo protocolo em todos os modelos do roteiro.  
Slides: 10.

## Regressão linear simples

Começamos com um modelo simples (`medv ~ lstat`) para criar a referência inicial de desempenho e interpretação.  
Slides: 8 e 11.

```{r simple_lm}
# Slides 8 e 11: regressão linear simples e ajuste
model_lm_simple <- reg_lm(formula = medv ~ lstat)
model_lm_simple <- fit(model_lm_simple, train)
summary(model_lm_simple$model)

train_pred_simple <- predict(model_lm_simple, newdata = train)
eval_reg(model_lm_simple, train$medv, train_pred_simple, "medv")$metrics

test_pred_simple <- predict(model_lm_simple, newdata = test)
eval_reg(model_lm_simple, test$medv, test_pred_simple, "medv")$metrics
```

O gráfico a seguir conecta o ajuste linear à nuvem de pontos, facilitando leitura de tendência e dispersão residual.  
Slides: 17.

```{r plot_simple}
# Slides 17: visualização do ajuste
ggplot(train, aes(x = lstat, y = medv)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, color = "red") +
  labs(title = "Regressao Linear Simples: medv ~ lstat")
```

Na sequência, comparamos dois tipos de intervalo:
- `prediction`: incerteza para uma nova observação individual;
- `confidence`: incerteza para a média esperada.  
Slides: 16.

```{r intervals}
# Slides 16: intervalos de predição e confiança
pred_int <- predict(model_lm_simple$model, newdata = test, interval = "prediction")
head(pred_int)

conf_int <- predict(model_lm_simple$model, newdata = test, interval = "confidence")
head(conf_int)
```

Os diagnósticos clássicos (`Residuals vs Fitted`, `QQ-plot`, `Scale-Location`, `Residuals vs Leverage`) ajudam a verificar premissas do modelo linear.  
Slides: 18.

```{r diagnostics}
# Slides 18: diagnóstico visual
par(mfrow = c(2, 2))
plot(model_lm_simple$model)
par(mfrow = c(1, 1))
```

## Regressão polinomial

Agora relaxamos a linearidade com termo quadrático para capturar curvatura entre `lstat` e `medv`.  
A comparação via ANOVA mostra se o ganho de complexidade é estatisticamente justificável.  
Slides: 21–26.

```{r poly_reg}
# Slides 21–26: regressão polinomial e overfitting
model_lm_poly2 <- reg_lm(formula = medv ~ poly(lstat, 2, raw = TRUE))
model_lm_poly2 <- fit(model_lm_poly2, train)
summary(model_lm_poly2$model)
anova(model_lm_simple$model, model_lm_poly2$model)
```

O gráfico abaixo permite inspeção visual direta da curvatura aprendida pelo modelo polinomial.  
Slide: 23.

```{r plot_poly}
# Slides 23: visualização da regressão polinomial
grid <- data.frame(lstat = seq(min(train$lstat), max(train$lstat), length.out = 200))
grid$pred <- predict(model_lm_poly2, newdata = grid)

ggplot(train, aes(x = lstat, y = medv)) +
  geom_point(alpha = 0.5) +
  geom_line(data = grid, aes(x = lstat, y = pred), color = "blue", linewidth = 1) +
  labs(title = "Regressao Polinomial (grau 2): medv ~ lstat")
```

## Regressão múltipla

Entramos em regressão múltipla para combinar variáveis explicativas e reduzir erro preditivo fora da amostra.  
Slides: 27–29.

```{r multiple_reg}
# Slides 27–29: regressão múltipla e interpretação
model_lm_multi <- reg_lm(formula = medv ~ lstat + rm + ptratio)
model_lm_multi <- fit(model_lm_multi, train)
summary(model_lm_multi$model)

train_pred_multi <- predict(model_lm_multi, newdata = train)
eval_reg(model_lm_multi, train$medv, train_pred_multi, "medv")$metrics

test_pred_multi <- predict(model_lm_multi, newdata = test)
eval_reg(model_lm_multi, test$medv, test_pred_multi, "medv")$metrics
```

A ANOVA entre modelos aninhados testa se incluir `nox` adiciona poder explicativo relevante.  
Slide: 30.

```{r anova_multi}
# Slides 30: ANOVA para regressão múltipla
model_lm_multi2 <- reg_lm(formula = medv ~ lstat + rm + ptratio + nox)
model_lm_multi2 <- fit(model_lm_multi2, train)
anova(model_lm_multi$model, model_lm_multi2$model)
```

Em seguida, calculamos VIF para monitorar multicolinearidade entre preditores, que pode inflar variâncias dos coeficientes.  
Slide: 31.

```{r vif}
# Slides 31: multicolinearidade (VIF)
vif_calc <- function(model) {
  X <- model.matrix(model)[, -1, drop = FALSE]
  vifs <- numeric(ncol(X))
  names(vifs) <- colnames(X)
  for (j in seq_len(ncol(X))) {
    # Regride cada preditor nos demais para obter R^2_j
    y <- X[, j]
    x <- X[, -j, drop = FALSE]
    r2 <- summary(lm(y ~ x))$r.squared
    # VIF_j = 1 / (1 - R^2_j)
    vifs[j] <- 1 / (1 - r2)
  }
  vifs
}
vif_calc(model_lm_multi2$model)
```

Esta visualização transforma o modelo em superfície de resposta para facilitar interpretação conjunta de duas variáveis contínuas.  
Slide: 32.

```{r surface}
# Slides 32: superfície de regressão múltipla
grid2 <- expand.grid(
  lstat = seq(min(train$lstat), max(train$lstat), length.out = 30),
  rm = seq(min(train$rm), max(train$rm), length.out = 30),
  ptratio = mean(train$ptratio),
  nox = mean(train$nox)
)
grid2$pred <- predict(model_lm_multi2, newdata = grid2)

ggplot(grid2, aes(x = lstat, y = rm, z = pred)) +
  geom_contour_filled() +
  labs(title = "Superficie de Regressao (medv ~ lstat + rm + ptratio + nox)")
```

Por fim, ajustamos um modelo com todos os preditores para ilustrar cenário de maior dimensionalidade e discutir risco de overfitting.  
Slide: 33.

```{r high_dim}
# Slides 33: alta dimensionalidade
model_lm_full <- reg_lm(formula = medv ~ .)
model_lm_full <- fit(model_lm_full, train)
summary(model_lm_full$model)
```

## Modelos supervisionados (DALToolbox)

Esta seção conecta a taxonomia de regressão dos slides com modelos não lineares/mais flexíveis, mantendo protocolo de treino e teste.  
Slides: 7, 19–20.

```{r dal_prep}
# Slides 19–20: extensões da regressão linear (modelos mais complexos)
# Complemento prático com DALToolbox
Boston_m <- as.matrix(Boston)
set.seed(1)
split_random_m <- sample_random()
split_random_m <- train_test(split_random_m, Boston_m)
boston_train <- split_random_m$train
boston_test <- split_random_m$test
```

Para leitura didática, em cada modelo observe principalmente:
1. diferença entre métricas de treino e teste (generalização);
2. relação entre complexidade do modelo e erro preditivo.

```{r dal_dtree}
# Slides 7: taxonomia (árvore de regressão)
model_dtree <- reg_dtree("medv")
model_dtree <- fit(model_dtree, boston_train)
train_pred <- predict(model_dtree, boston_train)
eval_reg(model_dtree, boston_train[, "medv"], train_pred, "medv")$metrics
test_pred <- predict(model_dtree, boston_test)
eval_reg(model_dtree, boston_test[, "medv"], test_pred, "medv")$metrics
```

No kNN, o parâmetro `k` controla o equilíbrio entre variância e viés.

```{r dal_knn}
# Slides 7: taxonomia (kNN para regressão)
model_knn <- reg_knn("medv", k = 5)
model_knn <- fit(model_knn, boston_train)
train_pred <- predict(model_knn, boston_train)
eval_reg(model_knn, boston_train[, "medv"], train_pred, "medv")$metrics
test_pred <- predict(model_knn, boston_test)
eval_reg(model_knn, boston_test[, "medv"], test_pred, "medv")$metrics
```

A MLP introduz não linearidade; compare com kNN e árvore para avaliar ganho real em teste.

```{r dal_mlp}
# Slides 7: taxonomia (MLP para regressão)
model_mlp <- reg_mlp("medv", size = 5, decay = 0.54)
model_mlp <- fit(model_mlp, boston_train)
train_pred <- predict(model_mlp, boston_train)
eval_reg(model_mlp, boston_train[, "medv"], train_pred, "medv")$metrics
test_pred <- predict(model_mlp, boston_test)
eval_reg(model_mlp, boston_test[, "medv"], test_pred, "medv")$metrics
```

Random Forest tende a reduzir variância de árvores individuais; aqui observamos estabilidade preditiva.

```{r dal_rf}
# Slides 7: taxonomia (Random Forest para regressão)
model_rf <- reg_rf("medv", mtry = 7, ntree = 30)
model_rf <- fit(model_rf, boston_train)
train_pred <- predict(model_rf, boston_train)
eval_reg(model_rf, boston_train[, "medv"], train_pred, "medv")$metrics
test_pred <- predict(model_rf, boston_test)
eval_reg(model_rf, boston_test[, "medv"], test_pred, "medv")$metrics
```

No SVR, `cost` e `epsilon` regulam margem e tolerância ao erro; observe sensibilidade das métricas.

```{r dal_svm}
# Slides 7: taxonomia (SVR)
model_svm <- reg_svm("medv", epsilon = 0.2, cost = 40.000)
model_svm <- fit(model_svm, boston_train)
train_pred <- predict(model_svm, boston_train)
eval_reg(model_svm, boston_train[, "medv"], train_pred, "medv")$metrics
test_pred <- predict(model_svm, boston_test)
eval_reg(model_svm, boston_test[, "medv"], test_pred, "medv")$metrics
```

Por fim, fazemos tuning para testar se a configuração automática supera o SVR definido manualmente.

```{r dal_tune}
# Slides 19: extensões e ajuste de modelos (tuning)
tune <- reg_tune(
  reg_svm("medv"),
  ranges = list(seq(0, 1, 0.2), cost = seq(20, 100, 20), kernel = c("radial"))
)
model_tuned <- fit(tune, boston_train)
train_pred <- predict(model_tuned, boston_train)
eval_reg(model_tuned, boston_train[, "medv"], train_pred, "medv")$metrics
test_pred <- predict(model_tuned, boston_test)
eval_reg(model_tuned, boston_test[, "medv"], test_pred, "medv")$metrics
```

Resumo pedagógico: o roteiro progride de um modelo linear simples para modelos mais expressivos, sempre validando ganho por desempenho e interpretabilidade.  
Isso ajuda a justificar tecnicamente quando vale sair de regressão linear clássica para métodos de maior complexidade.

## Referências
- Montgomery, D. C., Peck, E. A., Vining, G. (2012). *Introduction to Linear Regression Analysis*.
- James, G., Witten, D., Hastie, T., Tibshirani, R. (2021). *An Introduction to Statistical Learning*.
- Draper, N. R., Smith, H. (1998). *Applied Regression Analysis*.
- Breiman, L. (2001). Random Forests. *Machine Learning*.
- Drucker, H. et al. (1997). Support Vector Regression Machines.


